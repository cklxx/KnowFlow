services:
  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    environment:
      # Server Configuration
      - BIND_ADDRESS=0.0.0.0:3000
      - DATABASE_URL=sqlite:///data/knowflow.db

      # LLM Provider Configuration
      - LLM_PROVIDER=${LLM_PROVIDER:-remote}
      - LLM_TIMEOUT_SECS=${LLM_TIMEOUT_SECS:-30}

      # Remote LLM API (火山引擎 Doubao / OpenAI-compatible)
      - LLM_API_BASE=${LLM_API_BASE:-https://api.openai.com}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_MAX_TOKENS=${LLM_MAX_TOKENS:-4096}

      # Ollama Configuration (if using local provider)
      - OLLAMA_API_BASE=${OLLAMA_API_BASE:-http://127.0.0.1:11434}
      - OLLAMA_MODEL=${OLLAMA_MODEL:-llama3}
      - OLLAMA_KEEP_ALIVE=${OLLAMA_KEEP_ALIVE}
      - OLLAMA_TEMPERATURE=${OLLAMA_TEMPERATURE}
      - OLLAMA_TOP_P=${OLLAMA_TOP_P}
      - OLLAMA_REPEAT_PENALTY=${OLLAMA_REPEAT_PENALTY}
      - OLLAMA_NUM_PREDICT=${OLLAMA_NUM_PREDICT}
      - OLLAMA_NUM_CTX=${OLLAMA_NUM_CTX}
      - OLLAMA_NUM_THREADS=${OLLAMA_NUM_THREADS}
    volumes:
      - backend-data:/data
    ports:
      - "3000:3000"

  frontend:
    build:
      context: frontend
      dockerfile: Dockerfile
      args:
        VITE_API_BASE_URL: ${VITE_API_BASE_URL:-http://backend:3000}
    depends_on:
      - backend
    ports:
      - "80:80"
    environment:
      - VITE_API_BASE_URL=${VITE_API_BASE_URL:-http://backend:3000}

volumes:
  backend-data:
